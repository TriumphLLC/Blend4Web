
For Application Developers
**************************


Hello World!
============

The simplest Blend4Web app may look like this:

   <!DOCTYPE html>
   <html>
   <head>
   <script src="b4w.min.js"></script>
   <script>
   function hello() {
       var m_version = b4w.require("version");
       document.body.innerHTML = "Hello, Blend4Web " + m_version.version() + "!";
   }
   </script>
   </head>

   <body onload="hello()"></body>

   </html>

This app prints a message and the engine's version in the browser
window. Let's look at this example in detail. The engine library
(without add-ons) is embedded with the "<script src="...">" element.
Then, the app waits for the page to load and prints the current
version in the browser window. In this example, "version" is the only
used module which has a function with the same name - "version()". A
more detailed info about the usage of engine's modules and functions
can be found in the API documentation.

The compiled engine file "b4w.min.js" can be copied from the SDK's
"deploy/apps/common" directory and placed in the same directory as the
HTML file.


Loading a Scene into an App
===========================

To load a 3D scene you need:

1. Place a "<canvas>" element on a page for rendering.

2. Call the "m_main.init()" function with the created element id to
   init the WebGL context after the page is loaded.

3. Call the "m_data.load()" function to load a 3D scene.

   <!DOCTYPE html>
   <html>
   <head>
   <script src="b4w.min.js"></script>
   <script>
   function hello() {
       var m_main = b4w.require("main");
       var m_data = b4w.require("data");

       var canvas_elem = document.getElementById("canvas_id");
       m_main.init(canvas_elem);
       m_data.load("some_scene.json");
   }
   </script>
   </head>

   <body onload="hello()"><canvas id="canvas_id"></canvas></body>

   </html>

Note that a real app should include error checking, setting up the
engine before initializing and also a basic system for interacting
with the user.


Creating Apps Quickly
=====================

Creating an app from scratch can be a tedious task, especially for
beginners. To address this there is a special add-on for the engine
called "app":

   <!DOCTYPE html>
   <html>
   <head>
   <script src="b4w.full.min.js"></script>
   <script>

   var m_app = b4w.require("app");
   var m_data = b4w.require("data");

   m_app.init({
       canvas_container_id: "container_id",
       callback: load_cb
   });

   function load_cb()
       m_data.load("some_scene.json", loaded_cb);
   }

   function loaded_cb() {
       m_app.enable_controls();
       m_app.enable_camera_controls();
   }

   </script>
   </head>

   <body>
       <div id="container_id" style="width: 350px; height: 200px;"></div>
   </body>

   </html>

In this case the "app" module will create a "<canvas>" element inside
the container with the specified "container_id" id. Then it will
initialize the engine after the page is loaded and will finally
execute the "load_cb" callback.

Then the some_scene.json scene is loaded similar to the previous
example. The only difference is that after the scene is loaded, the
control system is initialized and camera movement with keyboard and
mouse (or sensor screen) becomes possible.

In case when the "app" module is used, it is necessary to specify
dimensions of the container element. Otherwise the created "<canvas>"
element will have zero dimensions.


Developing Apps Within the SDK
==============================

The SDK includes a script "apps_dev/project.py" for building
applications.

Example:

   ./project.py -p my_project_path -o advanced -b copy -v 15.02 -s my_resources_path

* Option ""-p"" points at the name of the directory where the
  project is.

* Option ""-a"" (not necessary) points at the html file relative to
  which the app will be constructed.

* Option ""-o"" (not necessary) is used to select the method ofjs
  files optimisation. Avaliable methods: "whitespace", "simple" (by
  default) and "advanced".

* With the ""-b"" parameter (optional) the engine's directory can be
  specified. Available options: **link** (default) - the engine file
  is linked from "deploy/apps/common/", **copy** - the engine file is
  copied into the directory with the built app, **combine** - the
  engine file is merged with the minified script located in the app's
  root, **compile** - required engine modules are compiled together
  with the app code.

* With the ""-d"" parameter (optional) the directory for the
  compiled app can be specified.

* With the ""-s"" parameter (optional) the directory can be
  specified where the scene resources are located.

* Option ""-e"" (not necessary) points at the directory inwhich the
  resources will be stored (relatively to the app's root).

* The ""-v"" parameter (optional) adds version statement to the urls
  of scripts and styles. This will force the browser to use updated
  scripts and styles instead of loading them from the browser cache.

* The ""-j"" parameter (optional) specifies JavaScript files to be
  excluded from compilation.

* The ""-c"" parameter (optional) specifies CSS styles to be
  excluded from compilation.

App structure:

* In the root of the directory the single html file must be stored
  if "-a" option is disabled

* Scripts and styles can be stored in the app's root and in the
  subfolders

How the app builder works:

* The project is being copied in the *deploy/apps/project_name/*
  directory.

* If "-d" option is enabled, the project is being copied in
  thecorresponding directory.

* Scripts and styles are compiled relative to the parent directory.


Non-FullScreen Web Apps
=======================

The Canvas element, to which the rendering is performed, can change
its position relative to the browser window. This can occur due to
some manipulations over the DOM tree, or as a result of page scrolling
which is especially relevant for non-fullscreen web applications.

In most cases this will not affect the performance of the app by any
means. However, some DOM events related to mouse cursor or touch
position may carry incorrect information. This occurs because the
coordinates obtained from the corresponding events are measured
relative to the origin of the browser window, while the engine works
with the coordinate space of the Canvas element itself (its origin is
located in the top left corner).

In order to obtain coordinates suitable for use in the engine, you can
transform them by using the "client_to_canvas_coords" method of the
"container" module:

   var m_cont   = require("container");
   var _vec2_tmp = new Float32Array(2);
   // . . .
   var canvas_xy = m_cont.client_to_canvas_coords(event.clientX, event.clientY, _vec2_tmp);
   // . . .

In order to obtain coordinates in the Canvas space, the engine should
know its position relative to the browser window. However, if this
position is subjected to changes during the work of the app (due to
scrolling for example), the Canvas position should be recalculated. To
do this automatically, you can set the "track_container_position"
property upon app initialization:

   exports.init = function() {
       m_app.init({
           // . . .
           track_container_position: true,
           // . . .
       });
       // . . .
   }

Please note, that this setting can lead to performance degradation in
some browsers (such as Firefox) due to frequent DOM tree accesses. If
the performance is critical, you can update the Canvas position
manually when it is really necessary. To do this, use the
"force_offsets_updating" and "update_canvas_offsets" methods instead
of the "track_container_position" setting, or even the lower-level
"set_canvas_offsets" method from the "container" module:

   var m_cont = require("container");
   // . . .
   m_cont.force_offsets_updating();
   // . . .
   m_cont.update_canvas_offsets();
   // . . .
   m_cont.set_canvas_offsets(offset_left, offset_top);
   // . . .


Code Examples
=============

The SDK includes the Code Snippets application which demonstrates how
to use the engine's functionality.

Currently, this application contains the following examples:
   * Canvas Texture - working with canvas textures

   * Camera Animation - procedural camera animation

   * Camera Move Styles - changing control modes for the camera

   * Custom Anchors - creating custom annotations

   * Dynamic Geometry - procedural geometry modification

   * Gyro (Mobile Only) - working with mobile devices' gyroscopes

   * Instancing - copying scene objects in runtime

   * Material API - tweaking material properties and replacing
     objects' materials

   * Morphing - using shape keys

The Code Snippets application is available at
"SDK/apps_dev/code_snippets/code_snippets_dev.html". It can be also
run by using a link in the "index.html" file located in the SDK root.


Resource Conversion
===================

Existing browsers do not fully support all possible media formats, so
in order to create cross-browser applications and for optimization
purposes we need to use a resource converter. The conversion is
performed according as follows:

for audio (convert_media):
   * ogg -> mp4

   * mp3 -> ogg

   * mp4 -> ogg

We recommend to use *Ogg* as the basic format. In this case the only
conversion required for cross-browser compatibility will be *ogg* to
*mp4*. Example of an input file: "file_name.ogg", example of an output
file: "file_name.altconv.mp4".

for video (convert_media):
   * webm -> m4v

   * m4v -> webm

   * ogv -> webm

   * webm -> seq

   * m4v -> seq

   * ogv -> seq

We recommend to use *WebM* as the basic format. In this case the only
conversion required for cross-browser compatibility will be *webm* to
*m4v* (*webm* to *seq* for iPhone). Example of an input file:
"file_name.webm", example of an output file: "file_name.altconv.m4v".

for images (convert_dds):
   * png -> dds

   * jpg -> dds

Example of an input file: "file_name.jpg", example of an output file:
"file_name.altconv.jpg.dds".

For the purpose of optimizing application performance it's possible to
use *min50* (halved) and *DDS* textures. In order to do this, we need
to pass the following parameters during the application
initialization.

   exports.init = function() {
       m_app.init({
           // . . .
           assets_dds_available: true,
           assets_min50_available: true,
           // . . .
       });
       // . . .
   }

The ".seq" file format is used for sequential video. This is applied
for IE 11 and iPhone because they are currently missing support for
standard video formats for textures. Using dds format for images is
more optimal compared to other formats.

To support a wider range of platforms, a Python script
(scripts/converter.py) for converting the source files into other
formats is included into the distribution. Run it with the command:

   > ./converter.py [-d file_path] resize_textures | convert_dds | convert_media

With the -d parameter you can specify the path to a directory in which
converting will take place.

To exclude some directory from resource conversion, it is enough to
put a file named ".b4w_no_conv" in it. This will not affect conversion
in nested directories.

The **resize_textures** argument is used for decreasing texture
resolution for the **LOW** mode.

The engine can use files which are manually created by a user if they
have the following names: "file_name.altconv.m4v",
"file_name.altconv.mp3" and so on. Such files should be placed in the
same directory as the mediafiles used in Blender.

You can also use the free and cross-platform application Miro Video
Converter to convert mediafiles.


Module System
=============

While the engine gives an app programmer an API in the scale of dozens
of modules, it occupies a single "b4w" namespace. To call a module's
method import it first with the "b4w.require" function.

It is possible to register external modules if their names do not
collide with already existing modules. A module can be registered with
a "b4w.register" call. Check if a module with some name already exists
with a "b4w.module_check" call.

Example:

   // check if module exists
   if (b4w.module_check("my_module"))
       throw "Failed to register module: my_module";

   // register my_module
   b4w.register("my_module", function(exports, require) {

       // import module "version"
       var m_version = require("version");

       // export print_build_date() from module "my_module"
       exports.print_build_date = function() {
           // exec function date() from module "version"
           console.log("Engine build date: " + m_version.date());
       }
   });

   // import module "my_module"
   var m_my_module = b4w.require("my_module");

   // exec function print_build_date() from module "my_module"
   m_my_module.print_build_date();


Event-Driven Model
==================

The event-driven model provides a universal interface for describing
the 3D scene's change of state. It simpifies the processing of physics
events and user actions.


Sensors
-------

The basic unit of the event-driven model is a sensor. A sensor is a
programming entity and can only be active (1, one) or inactive (0,
zero). Some sensors may carry a payload. For example the ray-tracing
sensor (Ray Sensor) provides the relative length of the intersection
ray.

Users cannot directly control sensors via the external API. Instead
all sensors must be present in one or multiple collections - so called
sensor manifolds. A manifold is a logic container associated with a
scene object. It generates a response to a defined set of sensor
events by executing a callback function. To define the manifold it is
required to have the following information (see also the API
documenation for decription of the "controls.create_sensor_manifold()"
function):

* An object to carry the manifold (e.g. a thrown object).

* An unique id of the manifold (e.g. "IMPACT").

* A callback execution mode (the options are: "CT_CONTINUOUS",

     "CT_LEVEL", "CT_SHOT", "CT_TRIGGER").

* An array of sensors.

* A logic function to define the combination of the sensor states
  for which the callback function is executed.

* A callback function.

* An optional parameter to pass into the callback function.


Example
-------

Lets consider the task to insonify the impact of a thrown stone. A
distinctive sound should be produced for impacting different media
(for example terrain and wall). There are collision meshes with
physical materials in the Blender scene, material ids are "TERRAIN"
and "WALL". There is also a physical object being thrown in the scene,
the object is named "Stone".

Lets define a collision sensor for each medium, by the type of the
sound produced.

   // import the modules
   var m_scenes = b4w.require("scenes");
   var m_controls = b4w.require("controls");

   // get the object being thrown
   var stone = m_scenes.get_object_by_name("Stone");

   // create the sensors
   var sensor_impact_terrain = m_controls.create_collision_sensor(stone, "TERRAIN");
   var sensor_impact_wall    = m_controls.create_collision_sensor(stone, "WALL");

Add the sensors into an array. Use the OR logic in the logic function.
Place the sound processing code in the callback function. Create the
sensor manifold with the "IMPACT" id and the CT_SHOT type.

   // array of the sensors
   var impact_sens_array = [sensor_impact_terrain, sensor_impact_wall];

   // manifold logic function
   var impact_sens_logic = function(s) {return (s[0] || s[1])};

   // callback
   var impact_cb = function(obj, manifold_id, pulse) {

       // NOTE: it's possible to play both sounds simultaneously

       if (m_controls.get_sensor_value(obj, manifold_id, 0) == 1) {
           // ...
           console.log("play the terrain impact sound");
       }

       if (m_controls.get_sensor_value(obj, manifold_id, 1) == 1) {
           // ...
           console.log("play the wall impact sound");
       }
   }

   // create the manifold
   m_controls.create_sensor_manifold(stone, "IMPACT", m_ctl.CT_SHOT,
       impact_sens_array, impact_sens_logic, impact_cb);

When the "Stone" object collides with any physical material of
"TERRAIN" or "WALL", the callback function is executed. Inside this
function we get the values of both sensors by their indices in the
sensor array (0 - "TERRAIN", 1 - "WALL"). The sensor value = 1
(active) means that the collision happened with the corresponding
physical material. As a result the corresponding sound is produced
(the code is not shown).


Quality Profiles
================

Several quality profiles are implemented in order to support platforms
with different functionality.

   * *low quality* (P_LOW) - a range of functions is turned off
     (such as shadows, dynamic reflection, postprocessing), the size
     of textures is halved when using a release version, anti-aliasing
     is disabled

   * *high quality* (P_HIGH) - all features requested by the scene
     are used, the anti-aliasing method is FXAA

   * *maximum quality* (P_ULTRA) - rendering resolution is doubled,
     resolution of shadow maps is increased, the anti-aliasing method
     is SMAA

[image]



Switching the quality profiles can be performed in runtime before
initialization of the WebGL context. The default profile is P_HIGH.

   var m_cfg = b4w.require("config");
   var m_main = b4w.require("main");

   m_cfg.set("quality", m_cfg.P_LOW);
   m_main.init(...);

Application developers can also set the **quality** parameter upon
engine initialization using the "app.js" add-on:

   var m_cfg = b4w.require("config");
   var m_app = b4w.require("app");

   m_app.init({
       canvas_container_id: "body_id",
       quality: m_cfg.P_HIGH
   });


SDK File Structure
==================

**apps_dev**
   source code of the applications (not all applications are available
   as a free version)

   **Makefile**
      the file for building all applications from the SDK

   **project.py**
      script for application developers

   **viewer**
      the sources files of the Viewer application

      **assets.json**
         meta data with information about scenes loaded by the Viewer

**csrc**
   source code (in C) of the binary part of the engine exporter and of
   the other utilities

**doc_src**
   source files of the current manual written in reST

**blender**
   source files of the Blender scenes (not all scenes are available as
   a free version)

**blender_scripts**
   exporter and utility scripts for Blender

**deploy**
   the resource directory for deploying on the server (scene source
   files, compiled applications and documentation)

   **api_doc**
      API documentation for developers (built automatically, based on
      the engine's source code)

   **apps**
      3D applications intended for deploying; the directory duplicates
      *apps_dev*

      **common**
         Compiled engine files. Shared by all applications from SDK
         (hence the name).

   **assets**
      downloadable resources: scenes, textures and sounds

   **doc**
      the current user manual in HTML format, built autamatically from
      *doc_src*

   **globals_detect**
      utility code for detecting global variables

   **tutorials**
      source files for the tutorials

**index.html** и **index_assets**
   main SDK webpage files

**license**
   files with license texts

**Makefile**
   makefile for building the engine, the applications, the
   documentation and for deploying on a remote server (not available
   as a free version)

**README.rst**
   README file

**scripts**
   utility scripts

   **chrome_debug.sh**
      script which starts Chrome in debugging mode

   **compile_b4w.py**
      script for building engine code and applications

   **converter.py**
      script which halves the texture dimensions, compresses the
      textures into the DDS format, converts sound files into mp4 and
      ogg formats

   **custom_json_encoder.py**
      fork of the json Python module, sorts the keys in reverse order

   **gen_glmatrix.sh**
      script for generating the math module based on the source code
      of glMatrix 2

   **graph.sh**
      SVG generator for the current scene graph, used for debugging
      rendering

   **memory.sh**
      script for checking memory (RAM) and video memory (VRAM)

   **plot.sh**
      debugging information graph builder

   **reexporter.py**
      script for automatic reexport of all scenes from the SDK

   **remove_alpha_channel.sh**
      script for removing the images alpha channel

   **report_unused_resources.py**
      script for checking of and reporting about unused resources
      (images and sounds referenced by the exported files)

   **screencast.sh**
      script for screen video recording

   **shader_analyzer.py**
      script starting the local web server which calculates complexity
      of the shaders

**shaders**
   GLSL shaders of the engine

**src**
   main source code of the engine's kernel

   **addons**
      source code of engine addons

   **ext**
      source code of the external declarations that form the engine's
      API

   **libs**
      source code of the libraries

**tools**
   Various tools for building the engine and applications

   **closure-compiler**
      Google Closure compiler, its externs and their generators

   **glsl**
      **compiler**
         compiler for the engine's GLSL shaders

      **pegjs**
         grammars of the PEG.js parser generator for implementing the
         GLSL preprocessor, and also the script for generating the
         parser modules from these grammars

   **yuicompressor**
      utility for compressing CSS files

**uranium**
   source code and building scripts of the Uranium physics engine (the
   fork of Bullet)

**VERSION**
   contains the current version of the engine


Canvas Textures
===============

Such textures can be accessed via the "textures" module. The workflow
is described below.

   var m_tex = require("textures");
   ...
   var ctx = m_tex.get_canvas_texture_context("canvas_id");
   ...
   // operations with canvas context
   ...
   m_tex.update_canvas_texture_context("canvas_id");

The context can be obtained with the "get_canvas_texture_context()"
function, to which a "canvas_id" identifier specified by the user in
Blender is passed. After any operations with the context the
"update_canvas_texture_context()" function should be executed, which
performs visualization of the changes of the "canvas_id" element.


Differences between Blrnder's and Blend4Web's coordinates
=========================================================

In blender's coordinate system the "UP" vector which points upwardsis
codirectional with the Z axis. Blend4Web, as OpenGL, uses Y axis in
this case. So the engine's coordinated are being rotated by 90° on X
axis relatively to Blender's.

[image]



API methods use the engine's coordinates so working with them can be
different than working in Blender.


Setting up the Browser for Loading Local Resources
==================================================

Since version 15.02 the Blend4Web SDK includes the development server
to solve the problem of loading local resources. Nevertheless the
following instructions can still be useful for developers.

The engine's renderer is a web application and it works when you view
an HTML file in a browser. After initialization the resources (scenes,
textures) are loaded. This process is subject to the same-origin
policy rule. In particular this rule forbids loading from a local
directory. A simple way to bypass this limitation is to set up the
browser for loading local resources (recommended). Another way is to
use a local web server.

Setting up the browser for loading local resources can be a simple and
versatile method to bypass security limitation. It is recommended to
use such browsers only for viewing local content.

*Chrome under Windows*:

Right click on the browser shortcut, select the "Properties" option
and add the "--allow-file-access-from-files" option to the executable
filepath (after the space symbol). Click "OK".


 [image]



For convenience create a copy of the shortcut and modify it for local
viewing while leaving the original shortcut untouched for normal
surfing.

*Chrome under OS X*:

Open Terminal and run the browser with the following parameter:



*Chrome/Chromium under Linux*:

Run the browser with the parameter:

   > google-chrome --allow-file-access-from-files

or:

   > chromium-browser --allow-file-access-from-files



*Firefox under Windows/Linux/OS X*:

Enter **about:config** to the browser's address bar, search for the
"security.fileuri.strict_origin_policy" parameter and double-click on
it to switch from "true" to "false".


 [image]



*Safari/OS X*:

Enable the "Develop" menu in Preferences, and activate the  "Disable
Local File Restrictions" option.

[image]


Running a Local Server
======================

You may prefer running your own web server instead of the development
server included in the SDK. An easy way to do this is running the web
server from the standard Python library.



*Under Windows*:

1. Download and install the latest Python distribution from the
   official site. When installing select the option for adding the
   executable to the path ("Add python.exe to Path").

2. Run Command Prompt.

3. Type the following command in the SDK's root directory:

      > python -m http.server



*Under Linux/OS X*:

1. If Python is not already present in your distribution, download
   and install its current version from the official site.

2. Run Terminal.

3. Type the following command in the SDK's root directory:

      > python3 -m http.server

After starting the server, open the index webpage with the SDK links
by navigating to http://localhost:8000.

If needed, a port number can be specified by the additional parameter:

   > python3 -m http.server 8080
