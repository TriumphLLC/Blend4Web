
For Application Developers
**************************


Hello World!
============

The simplest Blend4Web app may look like this:

   <!DOCTYPE html>
   <html>
   <head>
   <script src="b4w.min.js"></script>
   <script>
   function hello() {
       var m_version = b4w.require("version");
       document.body.innerHTML = "Hello, Blend4Web " + m_version.version() + "!";
   }
   </script>
   </head>

   <body onload="hello()"></body>

   </html>

This app prints a message and the engine's version in the browser
window. Let's look at this example in detail. The engine library
(without add-ons) is embedded with the "<script src="...">" element.
Then, the app waits for the page to load and prints the current
version in the browser window. In this example, "version" is the only
used module which has a function with the same name - "version()". A
more detailed info about the usage of engine's modules and functions
can be found in the API documentation.

The compiled engine file "b4w.min.js" can be copied from the SDK's
"deploy/apps/common" directory and placed in the same directory as the
HTML file.


Loading Scenes in Apps
======================

To load a 3D scene you need:

1. Place a "<canvas>" element on a page for rendering.

2. Call the "m_main.init()" function with the created element id to
   init the WebGL context after the page is loaded.

3. Call the "m_data.load()" function to load a 3D scene.

   <!DOCTYPE html>
   <html>
   <head>
   <script src="b4w.min.js"></script>
   <script>
   function hello() {
       var m_main = b4w.require("main");
       var m_data = b4w.require("data");

       var canvas_elem = document.getElementById("canvas_id");
       m_main.init(canvas_elem);
       m_data.load("some_scene.json");
   }
   </script>
   </head>

   <body onload="hello()"><canvas id="canvas_id"></canvas></body>

   </html>

Note that a real app should include error checking, setting up the
engine before initializing and also a basic system for interacting
with the user.


Module System
=============

While the engine gives an app programmer an API in the scale of dozens
of modules, it occupies a single "b4w" namespace. To call a module's
method import it first with the "b4w.require()" function.

It is possible to register external modules if their names do not
collide with already existing modules. A module can be registered with
a "b4w.register()" call. Check if a module with some name already
exists with a "b4w.module_check()" call.

Example:

   // check if module exists
   if (b4w.module_check("my_module"))
       throw "Failed to register module: my_module";

   // register my_module
   b4w.register("my_module", function(exports, require) {

       // import module "version"
       var m_version = require("version");

       // export print_build_date() from module "my_module"
       exports.print_build_date = function() {
           // exec function date() from module "version"
           console.log("Engine build date: " + m_version.date());
       }
   });

   // import module "my_module"
   var m_my_module = b4w.require("my_module");

   // exec function print_build_date() from module "my_module"
   m_my_module.print_build_date();


Creating Apps Quickly
=====================

Creating an app from scratch can be a tedious task, especially for
beginners. To address this there is a special add-on for the engine
called "app":

   <!DOCTYPE html>
   <html>
   <head>
   <script src="b4w.full.min.js"></script>
   <script>

   var m_app = b4w.require("app");
   var m_data = b4w.require("data");

   m_app.init({
       canvas_container_id: "container_id",
       callback: load_cb
   });

   function load_cb()
       m_data.load("some_scene.json", loaded_cb);
   }

   function loaded_cb() {
       m_app.enable_controls();
       m_app.enable_camera_controls();
   }

   </script>
   </head>

   <body>
       <div id="container_id" style="width: 350px; height: 200px;"></div>
   </body>

   </html>

In this case the "app" module will create a "<canvas>" element inside
the container with the specified "container_id" id. Then it will
initialize the engine after the page is loaded and will finally
execute the "load_cb()" callback.

Then the some_scene.json scene is loaded similar to the previous
example. The only difference is that after the scene is loaded, the
control system is initialized and camera movement with keyboard and
mouse (or sensor screen) becomes possible.

In case when the "app" module is used, it is necessary to specify
dimensions of the container element. Otherwise the created "<canvas>"
element will have zero dimensions.


Developing Apps Within the SDK
==============================


Creating a New App
------------------

Create a directory for the new project. Better do it in the
*SDK/apps_dev* directory. Also create the main HTML file.

During development it is more convenient to use the non-obfuscated
engine because it makes the debugging process much easier. To use the
non-obfuscated engine, go to the new app directory:

   cd <path_to_sdk>/apps_dev/example

For MS Windows users:

   cd <path_to_sdk>\apps_dev\example

Then run the script which generates paths to all required engine
files:

   python3 ../../scripts/mod_list.py

For MS Windows users:

   python ..\..\scripts\mod_list.py

Note: To run the scripts the Python 3.x needs to be installed in
  your system.

The console will print the list of modules - copy them and paste into
the main HTML file:

   <head>
       <meta charset="UTF-8">
       <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
       <script type="text/javascript" src="../../src/b4w.js"></script>
       <script type="text/javascript" src="../../src/anchors.js"></script>
       <script type="text/javascript" src="../../src/animation.js"></script>
       <script type="text/javascript" src="../../src/assets.js"></script>
       <script type="text/javascript" src="../../src/batch.js"></script>
       <script type="text/javascript" src="../../src/boundings.js"></script>
       <script type="text/javascript" src="../../src/camera.js"></script>
       . . .
   </head>


Preparing Assets
----------------

The next step is authoring scenes. It is convenient to store all
assets for your app in a single directory. Then the scene is assembled
in Blender and exported to the assets directory.

Converting resources is neccesary to develop cross-browser
applications.


App Logic Coding
----------------

The next step is writing scripts for app logic. The scripts are linked
to the main HTML file:

   <head>
   . . .
   <script type="text/javascript" src="example.js"></script>
   </head>

It is worth noting that the "get_std_assets_path()" function from the
*config.js* module is a convient method for loading .json files.

   m_data.load(m_config.get_std_assets_path() + "example/example.json", load_cb);

After building the finished app, the paths to assets will change.
Thus, using "get_std_assets_path()" wil allow you to avoid problems
with incorrect paths.


Building Apps
-------------

The SDK includes the script "apps_dev/project.py" for building
finished applications.

We recommend you to immediately complile your app in order to make
sure that it works. You can do it with the following command:

   ./project.py -p example -o advanced

For MS Windows users:

   python project.py -p example -o advanced

Note: For script operation it's required to install java and  set
  the PATH system variable.

By default, the project is copied as a whole to the
*deploy/apps/project_name/* directory. Scripts and styles are compiled
relative to the parent directory.


Exporting Apps Outside SDK
--------------------------

In order to export the finished app outside the SDK (for further
deploying) use the following command:

   ./project.py -p example -o advanced -b copy -s ../deploy/assets/example -d ../my_apps

For MS Windows users:

   python project.py -p example -o advanced -b copy -s ..\deploy\assets\example -d ..\my_apps

* Option ""-p"" points at the name of the directory where the
  project is.

* Parameter ""-a"" (optional) points at the html file relative to
  which the app will be constructed.

* Parameter ""-o"" (optional) is used to select the method ofjs
  files optimisation. Avaliable methods: "whitespace", "simple" (by
  default) and "advanced".

* With the ""-b"" parameter (optional) the engine's directory can be
  specified. Available options: **link** (default) - the engine file
  is linked from "deploy/apps/common/", **copy** - the engine file is
  copied into the directory with the built app, **combine** - the
  engine file is merged with the minified script located in the app's
  root, **compile** - required engine modules are compiled together
  with the app code.

* With the ""-d"" parameter (optional) the directory for the
  compiled app can be specified.

* With the ""-s"" parameter (optional) the directory can be
  specified where the scene resources are located.

* Parameter ""-e"" (optional) points at the directory in which the
  resources will be stored (relative to the app's root).

* The ""-v"" parameter (optional) adds version statement to the urls
  of scripts and styles. This will force the browser to use updated
  scripts and styles instead of loading them from the browser cache.

* The ""-j"" parameter (optional) specifies JavaScript files to be
  excluded from compilation.

* The ""-c"" parameter (optional) specifies CSS styles to be
  excluded from compilation.

Compiler Requirements

* In the root of the directory the single html file must be stored
  if "-a" option is disabled

* Scripts and styles can be stored in the app's root and in the
  subfolders


Resource Conversion
===================

Currently, browsers do not fully support all possible media formats,
so in order to create cross-browser applications (and also for
optimization purposes) we recommend you to use the resource converter.

To support a wider range of platforms, a Python script
(scripts/converter.py) for converting the source files into other
formats is included into the distribution. Run it with the command:

   > python3 <path_to_sdk>/scripts/converter.py [-d file_path] resize_textures | convert_dds | convert_media

For MS Windows users:

   cd <path_to_sdk>\scripts
   python converter.py [-d file_path] resize_textures | convert_dds | convert_media

Note: To run the scripts the Python 3.x needs to be installed in
  your system.

With the -d parameter you can specify the path to a directory in which
converting will take place.

To exclude some directory from resource conversion, it is enough to
put a file named ".b4w_no_conv" in it. This will not affect conversion
in nested directories.

The **resize_textures** argument is used for decreasing texture
resolution for the **LOW** mode.

Please make sure that you have all converter dependencies installed.
You can do it with the following command:

   > python3 <path_to_sdk>/scripts/converter.py check_dependencies

If some program is not installed, the following message will be
displayed:

*Couldn't find PROGRAM_NAME.*

The list of dependencies is listed in the following table:

+---------------------------------+---------------------------------+
| Name                            | Ubuntu 15.04 package            |
+=================================+=================================+
| ImageMagick                     | imagemagick                     |
+---------------------------------+---------------------------------+
| NVIDIA Texture Tools            | libnvtt-bin                     |
+---------------------------------+---------------------------------+
| Libav                           | libav-tools                     |
+---------------------------------+---------------------------------+
| FFmpeg                          | ffmpeg                          |
+---------------------------------+---------------------------------+

Note: Linux users can additionally install the package qt-faststart
  which is used to optimize loading media files.

For MS Windows users it is not necessary to install these packages
since they are already present in the SDK.

The conversion is performed as follows:

for audio (convert_media):
   * ogg -> mp4

   * mp3 -> ogg

   * mp4 -> ogg

We recommend to use "ogg" as a base format. In this case the only
conversion required for cross-browser compatibility will be "ogg" to
"mp4". Example of an input file: "file_name.ogg", example of an output
file: "file_name.altconv.mp4".

for video (convert_media):
   * webm -> m4v

   * m4v -> webm

   * ogv -> webm

   * webm -> seq

   * m4v -> seq

   * ogv -> seq

We recommend to use "WebM" as a base format. In this case the only
conversion required for cross-browser compatibility will be "webm" to
"m4v" ("webm" to "seq" for iPhone). Example of an input file:
"file_name.webm", example of an output file: "file_name.altconv.m4v".

for images (convert_dds):
   * png -> dds

   * jpg -> dds

Example of an input file: "file_name.jpg", example of an output file:
"file_name.altconv.jpg.dds".

For the purpose of optimizing application performance it's possible to
use "min50" (halved) and "DDS" textures. In order to do this, we need
to pass the following parameters during initialization of the
application:

   exports.init = function() {
       m_app.init({
           // . . .
           assets_dds_available: true,
           assets_min50_available: true,
           // . . .
       });
       // . . .
   }

The ".seq" file format is used for sequential video. This is applied
for IE 11 and iPhone because they are currently missing support for
standard video formats for textures. Using dds format for images is
more optimal compared to other formats.

The engine can use files which are manually created by a user if they
have the following names: "file_name.altconv.m4v",
"file_name.altconv.mp3" and so on. Such files should be placed in the
same directory as the mediafiles used in Blender.

You can also use the free and cross-platform application Miro Video
Converter to convert mediafiles.


Non-FullScreen Web Apps
=======================

The Canvas element, to which the rendering is performed, can change
its position relative to the browser window. This can occur due to
some manipulations over the DOM tree, or as a result of page scrolling
which is especially relevant for non-fullscreen web applications.

In most cases this will not affect the performance of the app by any
means. However, some DOM events related to mouse cursor or touch
position may carry incorrect information. This occurs because the
coordinates obtained from the corresponding events are measured
relative to the origin of the browser window, while the engine works
with the coordinate space of the Canvas element itself (its origin is
located in the top left corner).

1. If the top left corner of the Canvas element matches the top
   left corner of the browser window and is fixed in it's position
   (non- movable) then it's sufficient to use event.clientX and
   event.clientY coordinates of the input events or
   get_coords_x()/get_coords_y() methods.

   var m_mouse   = require("mouse");

   // . . .
   var x = event.clientX;
   var y = event.clientY;
   // . . .
   var x = m_mouse.get_coords_x(event);
   var y = m_mouse.get_coords_y(event);
   // . . .

2. In the case of the scrolled browser window, you have to use
   event.pageX and event.pageY coordinates.

   // . . .
   var x = event.pageX;
   var y = event.pageY;
   // . . .

3. In the case of more sophisticated manipulations with the Canvas
   element (scrolling of the page elements, displacement from the top
   level corner of the browser window, changes in the DOM-tree) you
   need to perform correct coordinate conversions. In order to obtain
   coordinates suitable for use in the engine, you can covert them by
   using the "client_to_canvas_coords()" method of the "container"
   module:

   var m_cont   = require("container");
   var _vec2_tmp = new Float32Array(2);
   // . . .
   var canvas_xy = m_cont.client_to_canvas_coords(event.clientX, event.clientY, _vec2_tmp);
   // . . .



   In order to obtain coordinates in the Canvas space, the engine
   should know its position relative to the browser window. However,
   if this position is subjected to changes during the work of the app
   (due to scrolling for example), the Canvas position should be
   recalculated. To do this automatically, you can set the
   "track_container_position" property upon app initialization:

   exports.init = function() {
       m_app.init({
           // . . .
           track_container_position: true,
           // . . .
       });
       // . . .
   }



   Please note, that this setting can lead to performance degradation
   in some browsers (such as Firefox) due to frequent DOM tree
   accesses. If the performance is critical, you can update the Canvas
   position manually when it is really necessary. To do this, use the
   "force_offsets_updating()" and "update_canvas_offsets()" methods
   instead of the "track_container_position" setting, or even the
   lower-level "set_canvas_offsets()" method from the "container"
   module:

   var m_cont = require("container");
   // . . .
   m_cont.force_offsets_updating();
   // . . .
   m_cont.update_canvas_offsets();
   // . . .
   m_cont.set_canvas_offsets(offset_left, offset_top);
   // . . .


Code Examples
=============

The SDK includes the Code Snippets application which demonstrates how
to use the engine's functionality.

Currently, this application contains the following examples:

   * Canvas Texture - working with canvas textures

   * Camera Animation - procedural camera animation

   * Camera Move Styles - changing control modes for the camera

   * Custom Anchors - creating custom annotations

   * Dynamic Geometry - procedural geometry modification

   * Gyro (Mobile Only) - working with mobile devices' gyroscopes

   * Instancing - copying scene objects in runtime

   * Material API - tweaking material properties and replacing
     objects' materials

   * Morphing - using shape keys

The Code Snippets application is available at
"SDK/apps_dev/code_snippets/code_snippets_dev.html". It can be also
run by using a link in the "index.html" file located in the SDK root.


Event-Driven Model
==================

The event-driven model provides a universal interface for describing
the 3D scene's change of state. It simpifies the processing of physics
events and user actions.


Sensors
-------

The basic unit of the event-driven model is a sensor. A sensor is a
programming entity and can only be active (1, one) or inactive (0,
zero). Some sensors may carry a payload. For example the ray-tracing
sensor (Ray Sensor) provides the relative length of the intersection
ray.

Users cannot directly control sensors via the external API. Instead
all sensors must be present in one or multiple collections - so called
sensor manifolds. A manifold is a logic container associated with a
scene object. It generates a response to a defined set of sensor
events by executing a callback function. To define the manifold it is
required to have the following information (see also the API
documenation for decription of the "controls.create_sensor_manifold()"
function):

* An object to carry the manifold (e.g. a thrown object).

* An unique id of the manifold (e.g. "IMPACT").

* Callback execution mode (the options are: "CT_CONTINUOUS",
  "CT_LEVEL", "CT_SHOT", "CT_TRIGGER", "CT_CHANGE").

* An array of sensors.

* A logic function to define the combination of the sensor states
  for which the callback function is executed.

* A callback function.

* An optional parameter to pass into the callback function.


Example
-------

Lets consider the task to insonify the impact of a thrown stone. A
distinctive sound should be produced for impacting different media
(for example terrain and wall). There are collision meshes with
physical materials in the Blender scene, material ids are "TERRAIN"
and "WALL". There is also a physical object being thrown in the scene,
the object is named "Stone".

Lets define a collision sensor for each medium, by the type of the
sound produced.

   // import the modules
   var m_scenes = b4w.require("scenes");
   var m_controls = b4w.require("controls");

   // get the object being thrown
   var stone = m_scenes.get_object_by_name("Stone");

   // create the sensors
   var sensor_impact_terrain = m_controls.create_collision_sensor(stone, "TERRAIN");
   var sensor_impact_wall    = m_controls.create_collision_sensor(stone, "WALL");

Add the sensors into an array. Use the "OR" logic in the logic
function. Place the sound processing code in the callback function.
Create the sensor manifold with the "IMPACT" id and the "CT_SHOT"
type.

   // array of the sensors
   var impact_sens_array = [sensor_impact_terrain, sensor_impact_wall];

   // manifold logic function
   var impact_sens_logic = function(s) {return (s[0] || s[1])};

   // callback
   var impact_cb = function(obj, manifold_id, pulse) {

       // NOTE: it's possible to play both sounds simultaneously

       if (m_controls.get_sensor_value(obj, manifold_id, 0) == 1) {
           // ...
           console.log("play the terrain impact sound");
       }

       if (m_controls.get_sensor_value(obj, manifold_id, 1) == 1) {
           // ...
           console.log("play the wall impact sound");
       }
   }

   // create the manifold
   m_controls.create_sensor_manifold(stone, "IMPACT", m_ctl.CT_SHOT,
       impact_sens_array, impact_sens_logic, impact_cb);

When the "Stone" object collides with any physical material of
"TERRAIN" or "WALL", the callback function is executed. Inside this
function we get the values of both sensors by their indices in the
sensor array (0 - "TERRAIN", 1 - "WALL"). The sensor value = 1
(active) means that the collision happened with the corresponding
physical material. As a result the corresponding sound is produced
(the code is not shown).


SDK File Structure
==================

**apps_dev**
   source code of the applications

   **code_snippets**
      source files of the Code Snippets app

   **dairy_plant**
      source files of the Dairy Plant demo (available only in SDK Pro)

   **fashion**
      source files of the Fashion Show demo (available only in SDK
      Pro)

   **firstperson**
      source files of the Farm demo (available only in SDK Pro)

   **flight**
      source files of the Island demo

   **gallery**
      source files of the Nature Morte demo (available only in SDK
      Pro)

   **new_year**
      source files of the New Year 2015 greeting card

   **Makefile**
      the file for building all applications from the SDK

   **project.py**
      script for application developers

   **victory_day_2015**
      source files of the V-Day 70 greeting card

   **viewer**
      the sources files of the Viewer application

      **assets.json**
         meta data with information about scenes loaded by the Viewer

   **webplayer**
      source files of the Web Player app

**blender**
   source files of the Blender scenes

**blender_scripts**
   exporter and utility scripts for Blender

**csrc**
   source code (in C) of the binary part of the engine exporter and of
   the other utilities

**deploy**
   the resource directory for deploying on the server (scene source
   files, compiled applications and documentation)

   **api_doc**
      API documentation for developers (built automatically, based on
      the engine's source code)

   **apps**
      3D applications intended for deploying; the directory duplicates
      *apps_dev*

      **common**
         Compiled engine files. Shared by all applications from SDK
         (hence the name).

   **assets**
      downloadable resources: scenes, textures and sounds

   **doc**
      the current user manual in HTML format, built autamatically from
      *doc_src*

   **globals_detect**
      utility code for detecting global variables

   **tutorials**
      source files for the tutorials

**doc_src**
   source files of the current manual written in reST

**index.html** and **index_assets**
   main SDK webpage files

**license**
   files with license texts

**Makefile**
   makefile for building the engine, the applications, the
   documentation and for deploying on a remote server (not available
   as a free version)

**README.rst**
   README file

**scripts**
   scripts

   **blend4web.lst**, **blend4web_sdk_free.lst** and
   **blend4web_sdk_pro.lst** (optional)
      lists of the files for building distributions

   **check_resources.py**
      script for checking of and reporting about unused resources
      (images and sounds referenced by the exported files)

   **compile_b4w.py**
      script for building engine code and applications

   **converter.py**
      script which halves the texture dimensions, compresses the
      textures into the DDS format, converts sound files into mp4 and
      ogg formats

   **custom_json_encoder.py**
      fork of the json Python module, sorts the keys in reverse order

   **gen_glmatrix.sh**
      script for generating the math module based on the source code
      of glMatrix 2

   **graph.sh**
      SVG generator for the current scene graph, used for debugging
      rendering

   **make_dist.py**
      distributions builder script

   **memory.sh**
      script for checking memory (RAM) and video memory (VRAM)

   **mod_list.py**
      script for generating the list of modules to use in new
      applications

   **plot.sh**
      debugging information graph builder

   **process_blend.py**
      script for automatic reexport of all scenes from the SDK

   **remove_alpha_channel.sh**
      script for removing the images alpha channel

   **screencast.sh**
      script for screen video recording

   **shader_analyzer.py**
      script starting the local web server which calculates complexity
      of the shaders

   **translator.py**
      script for building addon translations

**shaders**
   GLSL shaders of the engine

**src**
   main source code of the engine's kernel

   **addons**
      source code of engine addons

   **ext**
      source code of the external declarations that form the engine's
      API

   **libs**
      source code of the libraries

**tools**
   Various tools for building the engine, apps or convert resources

   **converter_utils**
      binary builds of the tools for resource conversion

   **closure-compiler**
      Google Closure compiler, its externs and their generators

   **glsl**
      **compiler**
         compiler for the engine's GLSL shaders

      **pegjs**
         grammars of the PEG.js parser generator for implementing the
         GLSL preprocessor, and also the script for generating the
         parser modules from these grammars

   **yuicompressor**
      utility for compressing CSS files

**uranium**
   source code and building scripts of the Uranium physics engine (the
   fork of Bullet)

**VERSION**
   contains the current version of the engine


Setting up the Browser for Loading Local Resources
==================================================

Since version 15.02 the Blend4Web SDK includes the development server
to solve the problem of loading local resources. Nevertheless the
following instructions can still be useful for developers.

The engine's renderer is a web application and it works when you view
an HTML file in a browser. After initialization the resources (scenes,
textures) are loaded. This process is subject to the same-origin
policy rule. In particular this rule forbids loading from a local
directory. A simple way to bypass this limitation is to set up the
browser for loading local resources (recommended). Another way is to
use a local web server.

Setting up the browser for loading local resources can be a simple and
versatile method to bypass security limitation. It is recommended to
use such browsers only for viewing local content.

*Chrome under Windows*:

Right click on the browser shortcut, select the "Properties" option
and add the "--allow-file-access-from-files" option to the executable
filepath (after the space symbol). Click "OK".


 [image]



For convenience create a copy of the shortcut and modify it for local
viewing while leaving the original shortcut untouched for normal
surfing.

*Chrome under OS X*:

Open Terminal and run the browser with the following parameter:



*Chrome/Chromium under Linux*:

Run the browser with the parameter:

   > google-chrome --allow-file-access-from-files

or:

   > chromium-browser --allow-file-access-from-files



*Firefox under Windows/Linux/OS X*:

Enter **about:config** to the browser's address bar, search for the
"security.fileuri.strict_origin_policy" parameter and double-click on
it to switch from "true" to "false".


 [image]



*Safari/OS X*:

Enable the "Develop" menu in Preferences, and activate the  "Disable
Local File Restrictions" option.

[image]


Running a Local Server
======================

You may prefer running your own web server instead of the development
server included in the SDK. An easy way to do this is running the web
server from the standard Python library.



*Under Windows*:

1. Download and install the latest Python distribution from the
   official site. When installing select the option for adding the
   executable to the path ("Add python.exe to Path").

2. Run Command Prompt.

3. Type the following command in the SDK's root directory:

      > python -m http.server



*Under Linux/OS X*:

1. If Python is not already present in your distribution, download
   and install its current version from the official site.

2. Run Terminal.

3. Type the following command in the SDK's root directory:

      > python3 -m http.server

After starting the server, open the index webpage with the SDK links
by navigating to http://localhost:8000.

If needed, a port number can be specified by the additional parameter:

   > python3 -m http.server 8080


Quality Profiles
================

Several quality profiles are implemented in order to support platforms
with different functionality.

   * *low quality* ("P_LOW") - a range of functions is turned off
     (such as shadows, dynamic reflection, postprocessing), the size
     of textures is halved when using a release version, anti-aliasing
     is disabled

   * *high quality* ("P_HIGH") - all features requested by the scene
     are used, the anti-aliasing method is FXAA

   * *maximum quality* ("P_ULTRA") - rendering resolution is
     doubled, resolution of shadow maps is increased, the anti-
     aliasing method is SMAA

[image]



Switching the quality profiles can be performed in runtime before
initialization of the WebGL context. The default profile is "P_HIGH".

   var m_cfg = b4w.require("config");
   var m_main = b4w.require("main");

   m_cfg.set("quality", m_cfg.P_LOW);
   m_main.init(...);

Application developers can also set the **quality** parameter upon
engine initialization using the "app.js" add-on:

   var m_cfg = b4w.require("config");
   var m_app = b4w.require("app");

   m_app.init({
       canvas_container_id: "body_id",
       quality: m_cfg.P_HIGH
   });
